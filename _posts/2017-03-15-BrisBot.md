---
layout: post
title:  "Using Brisbot to answer the many questions children ask"
author: "Simon Jäger"
author-link: "https://twitter.com/simonjaegr"
#author-image: "{{ site.baseurl }}/images/authors/photo.jpg"
date: 2017-04-21
categories: [Conversations as a Platform]
color: "blue"
#image: "{{ site.baseurl }}/images/imagename.png" #should be ~350px tall
excerpt: This project describes building a chat bot that can reach children wherever they may be, while tackling some of the concerns that come into play when building experiences for children.
language: [English]
verticals: [Social]
---

Some children hesitate to pick up the phone and call a helpline. It takes courage, no matter how big or small the problem is. Being able to speak to someone is always a great start. 

This project describes building a chat bot that can reach children wherever they may be, be it Messenger, Kik, Skype, Web, or SMS. By expanding the options available to children with questions or concerns, we allow for a better reach.

The bot has the following objectives:
- To bring awareness to more children that may not be sure if they can call a helpline, which helps children to anonymously ask questions and get the conversation started, and offload the helpline with the lighter issues and concerns. 
- To help the child engage with the helpline, serving as a stepping stone for any child that hasn't yet built up the courage to make the call. 
- To create awareness for parents and the public about the work and service that the bot provides.

The scope for the project was to architect the solution from the bottom up. This included designing and implementing the data layer, Web APIs, bot, and hosting, while tackling some of the concerns that come into play when building experiences for children. All of this was done with a mission to explore the technologies with the customer and create a proof of concept (POC).

> We believe that no matter what the problem is, talking to someone is always a good start. Children communicate in many ways and on many platforms, but some hesitate to call the Bris helpline for support.
>
> ——<cite>Silvia Ernhagen, Director of Communications at BRIS</cite>

 
### Key technologies

- **[Bot Framework](https://dev.botframework.com/)** – Bot framework, tools and distribution
- **[ASP.NET/ASP.NET Core](https://www.asp.net/)** – Web application framework
- **[Entity Framework](https://docs.microsoft.com/en-us/ef/)** – ORM framework
- **[Web Apps feature of Microsoft Azure App Service](https://azure.microsoft.com/en-gb/services/app-service/web/)** – Hosting both the production and staging environment
- **[Microsoft Azure SQL Database](https://azure.microsoft.com/en-us/services/sql-database/?b=16.50)** – Data storage

### Core team

- **Anders Wedahl** – Business Development, Microsoft 
- **Tess Ferrandez** – Development Lead, Microsoft
- **Anders Thun** – Developer, Microsoft
- **Dag König** – Developer, Microsoft
- **Peter Bryntesson** – Developer, Microsoft
- **Simon Jäger** – Developer, Microsoft
- **Magnus Jägerskog** – Secretary General, BRIS
- **Anna Albinsson** – HR Manager and Head of Cabinet, BRIS
- **Ulrika Eriksson** – Head of Support Unit, BRIS
- **Silvia Ernhagen** – Director of Communications, BRIS
- **Sofia Edvardsen** – Legal Representation, Sharp Cookie Advisors
- **Mattias Alfborger** – Interactive Art Director, Garbergs
- **Andreas Engstrand** – Project Leader, Garbergs


## Customer profile

BRIS—Children´s Rights in Society—is a politically and religiously independent children's rights organization that listens to, supports, and strengthens children and young adults' rights in society. It conducts public opinion work to seek the attention of politicians and decision‐makers to child rights' issues on the basis of children's stories, and is a consultative body for legislative actions that affect children and young adults.

BRIS is a member‐organization financed by member fees and contributions from businesses, private donors, investment funds, and partly from the state. Its headquarters are located in Stockholm, and it has five regional offices located in Malmö, Göteborg, Norrköping, Stockholm, and Umeå.

BRIS' support services offer children and young adults up to 18 years old a secure, anonymous, and free way to email, chat, or call a counselor. Since its inception, physical abuse has been a central issue for BRIS, but support is also about other important issues where the child is mistreated, having problems, or needs support and advice from knowledgeable and empathetic adults. It has employed counselors in the Support Services division.

[BRIS in English](https://www.bris.se/languages/)  
<br/>
![Bris logo]({{ site.baseurl }}/images/brisbot/logo.png)  
<br/>
## Problem statement

To ensure that the customer would be able to maintain and further develop the solution, we targeted the selected technologies with regards to the customer's competencies and demands. Because the customer is a non-profit organization, cost played a role in architecting the solution; we had to design with low cost in mind.

One of the ideas behind this effort was to solve an existing challenge: to reach children wherever they are. This meant bringing the solution to multiple channels (such as Messenger, Kik, Skype, SMS, and the Web) with a common code base. 

In addition, the solution needed to support multiple languages and offer a very delicate interaction with its users (children). Because children might bring questions and concerns about deeply personal and sensitive matters, it was crucial that the solution could respond clearly and appropriately. 

To summarize, we concluded that the following challenges existed:
- Align technologies and services to the customer's competencies and demands.
- Align technologies and services to minimize cost.
- Support multiple channels with a common code base.
- Support multiple languages.
- Align the user experience to delicately address the questions and concerns expressed by the users (children).

### A data-driven bot

The solution has more than 600 responses, where each response is localized in two languages. Each response can have up to 10 different answers (actions).

Because of the number of dialogs and prompts this generates, hard-coding the solution isn't a viable option. Also, maintaining something like this would be difficult and time-consuming.

With that in mind, the best decision was to make the bot completely data-driven; that is, store the responses and actions in data storage, while allowing any editing to potentially be done through a management interface.  
<br/>
![Bot running in Messenger]({{ site.baseurl }}/images/brisbot/fb-bot.png)  
<br/>
For each conversation, the bot goes through the following loop: 

1. Bot sends a response with one or more text messages.

2. Bot sends a set of options (actions) for next steps.

3. User selects one of the buttons, and a message is sent back to the bot.

4. Bot retrieves the next response from the Web API (based on the action) and continues with step #1.

The bot currently does not handle free-text, so any text that does not correspond to a pre-defined action will yield a **default response**. This default response tells the user that the bot does not understand free-text.

#### Database model

In the database, the actions and responses are stored like this.   
<br/>
![Database model]({{ site.baseurl }}/images/brisbot/snip_20170323102337.png)  
<br/>
#### The anatomy of a response

A given response can have one or more **text** prompts (per language) and a set of next **actions**.  
<br/>
![Bot responses]({{ site.baseurl }}/images/brisbot/snip_20170323112500.png)  
<br/>
The first response in the diagram contains one **text** prompt ("What do you want to talk about?") and six actions.
Each action has an **action text**; for example, "I have a question/I wanna have a look around" and a **short action text** shown on the button "Question/Look around."

In this case the user selected action 4 with the **short action text** "Bris." This sends a **PostBack** action with the **Title** "Bris" and the **Value** **`action:1234:`** where `1234` is the id of the next response we should send to the user.

The PostBack allows us to send "hidden" data back, and we have created a simple protocol `action:[next_response_id]:[side_effects]` that gives us all the data we need to move the conversation forward. We send this `next_response_id` to the Web API, which then returns a new response for us to display.

#### Text options

In the first response, we only had one prompt. In the next response we see that the bot sends two separate messages (to make it more readable). When we have more than one prompt for the user, we store it in the database as `string1##string2##string3`.

We also have a different multi-text situation. For example, in the error response, we don’t always want to respond the same way. In this case we store multiple text entries in the Texts table, and the Web API will randomize which of the texts we get.

Finally, the texts are also localized into English and Swedish, and we have separate text entries in the Texts table for the different languages.

#### Side effects

A side effect is something that needs to occur in addition to sending the next response.

For example, if the user selects the action "Svenska tack!" (Swedish please!) we need to switch the language to Swedish before sending the next response.

#### Start over 

Sometimes you can get lost when talking to a bot because the "page structure" is not that visible. To help the user, we have added a default action, which is to start over.  
<br/>
![Start over action]({{ site.baseurl }}/images/brisbot/snip_20170323103620.png)  
<br/>
This is supposed to be included in most responses. There is a property in the response named `IncludeDefaultAction` that you can set to include this default action.

#### Other media

In some cases, you may want to show an image, a video, or a link as part of the response. This is what the `MediaType` is for.   
<br/>
![Other media]({{ site.baseurl }}/images/brisbot/snip_20170323112555.png)  
<br/>
In this example, the response to email has the `MediaType = "link"` and points to a link with the text "BRIS-mail" and the link [http://www.bris.se](http://www.bris.se). This then displays as a separate card at the end of the prompts with a link action button that the user can select to get to the BRIS website.

#### Starting conversations and handling errors 

In the database, we can also configure a set of messages and actions that we can use in specific situations. These are configured in the config table.

#### Start action

This action is triggered when a user adds the bot to the contact list or starts a new conversation with the bot.  
<br/>
![Start action]({{ site.baseurl }}/images/brisbot/snip_20170323103506.png)  
<br/>
#### Default action

The default action is added to a response if the `IncludeDefaultAction` is true. In our case, this is the **start over** action.  
<br/>
![Default action]({{ site.baseurl }}/images/brisbot/snip_20170323103620.png)  
<br/>
#### Default response 

At the moment, we don’t allow free-text. Whenever a user writes anything in free-text, we respond with the default response.  
<br/>
![Default response]({{ site.baseurl }}/images/brisbot/snip_20170323104820.png)  
<br/>
#### Error response 

The error response is displayed whenever we have an unhandled exception.

#### Try it out

As the dialog is completely data-driven, the code for the bot is quite generic. We have placed the code for the bot on GitHub [dynamic-dialog-bot-sample](https://github.com/simonjaeger/dynamic-dialog-bot-sample) if you want to try it out.

## Solution and steps

The solution was created in multiple parts in parallel by the team. This included the data layer, the Web API, and the bot itself. Both the Web API and the bot were hosted in [Web Apps](https://azure.microsoft.com/en-us/services/app-service/web/), which is included within [Azure App Service](https://azure.microsoft.com/en-us/services/app-service/). 

The bot can be consumed via the bot channels (Messenger, Kik, Skype, SMS, Web), but also embedded on the customer's page as a bot client.  
<br/>
![Bris logo]({{ site.baseurl }}/images/brisbot/architecture.png)  
<br/>
### Data

Many involved in the project had existing experiences with SQL, which made using [Azure SQL Database](https://azure.microsoft.com/en-us/services/sql-database/?b=16.50) an obvious choice for the data layer. Not only could we leverage existing knowledge within the team, but this PaaS ([Platform as a Service](https://azure.microsoft.com/en-us/overview/what-is-paas/)) component allowed us to focus on the data storage/functionality itself rather than configuring and maintaining a SQL Server environment. In addition, it made it easier for the customer to maintain the solution. 

We applied TDE ([Transparent Data Encryption](https://msdn.microsoft.com/library/dn948096)) on the Azure SQL Database. This made it easy for us to work as we have in the past with SQL solutions, while transparently encrypting the data at rest.

As for data storage, the solution leverages emoticons in the experience. This meant that we needed to be aware of the encoding when storing the data (strings). Azure SQL Database (and many other solutions) supports character data types with [Unicode](https://msdn.microsoft.com/en-us/library/windows/desktop/dd374081.aspx) data. These are [nchar and nvarchar](https://msdn.microsoft.com/en-us/library/ms186939.aspx). 

Following is an example of using these data types in Azure SQL Database. By appending the `N` character before any strings, the data will be treated as Unicode.

```sql
CREATE TABLE dbo.UnicodeTable
(
    NCharColumn nchar(20),
    NVarCharColumn nvarchar(25)
);
GO

INSERT INTO dbo.UnicodeTable
VALUES (N'Test data 👋', N'More test data 👤');
GO

SELECT NCharColumn, NVarCharColumn
FROM dbo.UnicodeTable;
```

These strings are also localized, supporting both English and Swedish in the current scope of the project. The language-specific string is acquired by using a language code ("en"/"sv") as a partial key.

Furthermore, we wanted to make sure that the data is replicated. As with TDE, this was merely a feature to turn on in Azure SQL Database, [Active Geo-Replication](https://docs.microsoft.com/en-us/azure/sql-database/sql-database-geo-replication-overview). This ensures that the data is actively replicated to a different region. This replicated Azure SQL Database is also readable, allowing the solution to offload less critical requests to it. 

In addition, in the unlikely event of a service disruption, the customer can do a failover to the replicated Azure SQL Database.

### Web API

The Web API is an isolated layer in the architecture, which provides the bot with its data. The Web API reads the data from the Azure SQL Database and returns it through [ASP.NET Core Controllers](https://docs.microsoft.com/en-us/aspnet/core/tutorials/first-mvc-app/adding-controller).

As the Web API needed to be able to deliver localized data, we decided to leverage request and response headers for the matter. Picking up the Accept-Language header in the Controller methods, we were able to feed the data back to the client in the proper language. This was created like this: 

```csharp
string language = "sv";

// Supports "en" and "sv". Countries not included.
if (Request != null && ((FrameRequestHeaders)Request.Headers).HeaderAcceptLanguage.Count > 0)
{
    // Get the language from the Accept-Language header.
    language = ((FrameRequestHeaders)Request.Headers).HeaderAcceptLanguage[0];

    // Validate the language. Default to "sv".
    if (language != "sv" && language != "en")
    {
        language = "sv";
    }
}

// Get the response.
var result = _repository.GetResponse(id, language);
```

Notice that we covered the case where an Accept-Language header isn't present, defaulting to "sv" (Swedish). 

We also wanted to keep the client informed about the language of the responses received. We achieved this by using the Content-Language header in the responses:

```csharp
// Append the language to the Content-Language header.
((FrameResponseHeaders)Response.Headers).HeaderContentLanguage = new StringValues(language);
return Ok(result);
```

To interact with Azure SQL Database, we decided to leverage [Entity Framework Core](https://docs.microsoft.com/en-us/ef/core/index) in the Web API. This allowed us to map objects and relationships within .NET for the data layer. All of this is described within a [DbContext](https://docs.microsoft.com/en-us/ef/core/miscellaneous/configuring-dbcontext), which is the primary bridge between the Web API and the Azure SQL Database.

We created the entity object for the localized strings.

```csharp
public class DbText
{
    public string Id { get; set; }
    public string LanguageId { get; set; }
    public int Ordinal { get; set; }
    public string Content { get; set; }
}
```

The set of these entities is created in the DbContext.

```csharp
public DbSet<DbText> Texts { get; set; }
```

The key is defined within the override `OnModelCreating` method in the DbContext. Notice that this set uses partial keys (`Id, LanguageId, Ordinal`). 

```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    ...
    modelBuilder.Entity<DbText>()
        .HasKey(t => new { t.Id, t.LanguageId, t.Ordinal });
}
```

The localized strings are then acquired by using the following method.

```csharp
public DbText GetText(string textId, string languageId)
{
    var texts = Texts.Where(t => t.Id == textId && t.LanguageId == languageId);
    if (texts.Any())
    {
        var r = new Random((int)DateTime.Now.Ticks);
        var ordinal = r.Next(texts.Count() - 1) + 1;
        return texts.Where(t => t.Ordinal == ordinal).FirstOrDefault();
    }
    return null;
}
```

Many of the strings have alternate versions to create a sense of variety in the bot experience. This method helps to randomize the result.

### Bot

#### Shared code

The bot relies entirely on the Web API for its data. Because the bot receives what the Web API sends, we could share common definitions for these objects (DTDs/DTOs). 

The only difference between the bot and the Web API is that these models need to be marked as [Serializable](https://msdn.microsoft.com/en-us/library/system.serializableattribute.aspx) for the bot. We used the `!NETCOREAPP1_0` flag for specifying the bot specific code.

```csharp
#if !(NETCOREAPP1_0)
    [Serializable]
#endif
    public class Link
    {
        public string Id { get; set; }
        public string Url { get; set; }
        public string Thumbnail { get; set; }
        public string Title { get; set; }
    }
```

These models were then packaged in a separate folder and linked into the Web API and bot projects.

#### Dependency injection

When building and collaborating on the project, we leveraged mock services and mock data as different layers of the solution were being developed. Working in parallel and simulating depedencies allowed us to develop and test faster.

To make this workflow possible, we used the [Autofac](https://autofac.org/) dependency injection framework. Dependency injection is a technique for injecting objects into clients (such as dialogs and controllers) rather than having the client itself building the service. 

The bot communicates with its Web API through an `IResponseService` dependency. This service is defined like this.

```csharp
public interface IResponseService
{
    Task<Config> GetConfigAsync(string language);

    Task<Response> GetResponseAsync(string responseId, string language);
}
```

As the bot starts, it registers the dependency resolver through the startup method (Application_Start) in ASP.NET.

```csharp
public static void RegisterBot(HttpConfiguration config)
{
	var builder = new ContainerBuilder();

	// Register bot builder modules.
	builder.RegisterModule(new DialogModule());
	builder.RegisterModule(new BrisModule());

	// Register API controllers.
	builder.RegisterApiControllers(Assembly.GetExecutingAssembly());

	// Create the container and assign the dependency resolver.
	var container = builder.Build();
	config.DependencyResolver = new AutofacWebApiDependencyResolver(container);
}
```

Following is the module that is used in the previous method. This registers the bot dialog and its services. Note that a `MockupResponseService` type (mock implementation of the service) is registered as the provider for any `IResponseService` dependencies.

After the solution is in production, it will swap the `MockupResponseService` for an implementation (`ResponseService`) that consumes the real Web API.

```csharp
public sealed class BrisModule : Module
{
    protected override void Load(ContainerBuilder builder)
    {
        base.Load(builder);

        // Register top level dialog.
        builder.RegisterType<BrisDialog>()
            .As<IDialog<object>>()
            .InstancePerDependency();

        // Register services.
        builder.RegisterType<MockupResponseService>()
            .Keyed<IResponseService>(FiberModule.Key_DoNotSerialize)
            .AsImplementedInterfaces()
            .SingleInstance();
    }
}
```

Notice how we registered the dependency differently. While the dialogs need to be resolved per dependent (as they are instantiated per bot conversation), the `IResponseService` implementation can be shared between dependents.

Following is a dialog that depends on an `IResponseService` implementation. The dependency resolver will take care of injecting the implementation whenever this dialog is resolved.

```csharp
[Serializable]
public class BrisDialog : IDialog<object>
{
    private readonly IResponseService _responseService;

    public BrisDialog(IResponseService responseService)
    {
        SetField.NotNull(out _responseService, nameof(responseService), responseService);
    }
...
```

This technique is useful when developing a solution or having multiple implementations of a dependency (test, production, etc.).

#### Language

Because much of the data (strings) is localized, the bot needs to specify the preferred language when consuming the Web API. When building bots for .NET, the preferred language can be acquired by looking at the thread culture. The two-letter language code used by the Web API can be found by using the `TwoLetterISOLanguageName` property of the culture.

```csharp
private void SetLanguageBasedOnThread()
{
    var preferredLanguage = Thread.CurrentThread.CurrentUICulture.TwoLetterISOLanguageName;
    if (preferredLanguage == "en")
        _language = "en";
}
``` 

After the language code had been figured out, we attached it to any requests towards the Web API by using the Accept-Language header.

```csharp
private async Task<T> GetAsync<T>(Uri requestUri, string language) where T : class
{
    try
    {
        // Create the HTTP client.
        var httpClient = new HttpClient();

        // Add the Accept-Language header.
        httpClient.DefaultRequestHeaders.AcceptLanguage.Add(new StringWithQualityHeaderValue(language));

        // Get the response.
        var response = await httpClient.GetAsync(requestUri);
        var str = await response.Content.ReadAsStringAsync();

        if (!response.IsSuccessStatusCode)
        {
            return null;
        }

        // Deserialize the response body.
        var result = JsonConvert.DeserializeObject<T>(str);
        return result;
    }
    catch
    {
        // Ignored.
    }
    return null;
}
```

The language of the bot can also be altered by using an option given to the user when starting a conversation with the bot. This simply alters the same private variable provided to the previous method. 

Even though you can figure out a language code from the current thread, it may not be the preferred language of the user. Providing a separate  option to specify the language allows for a better experience. The thread culture may also be an unsupported language; at this point we fall back to a default language.

Additionally, a great way of bringing more personality to the bot is with the use of emoticons. Because emoticons are widely used within the many bot channels (Messenger, Kik, Skype, SMS, Web), we made sure to leverage proper Unicode encoding in the data layer to provide localized strings with emoticons.  
<br/>
![Bot Framework Emulator Running Bot]({{ site.baseurl }}/images/brisbot/emulator2.png)  
<br/>
#### Typing

One thing you can do to improve the experience of your bot is to make it more personal. We chose to show the user that the bot is working on a response (in the clients in which this is possible). 

We did this by using a typing activity, which will indicate to the user that the bot is typing. Much like showing a progress indicator in an app, this is a great way of providing some input to the user while the bot is thinking. 

In addition, we simulated a random delay on the response in some cases where a response could be returned instantly. This creates a more human-like feeling when interacting with the bot.

We implemented this feature like this.

```csharp
private static async Task SendTypingMessageAsync(IDialogContext context, bool addDelay = false)
{
	// Create the "typing" message.
	var message = context.MakeMessage();
	message.Type = ActivityTypes.Typing;

	// Send the message.
	await context.PostAsync(message);

	// Simulate a delay if requested. 
	if (addDelay)
	{
		await Task.Delay((int)(_random.NextDouble() * 1000));
	}
}
```

Be aware that some bot channels do not support this feature (such as SMS).  
<br/>
![Bot Typing...]({{ site.baseurl }}/images/brisbot/typing.png)  
<br/>
#### Start response

We wanted to make the bot act as soon as it was added to a conversation. This is great for giving the user a sense of what the bot can do upfront. To do this, we had to first and foremost figure out whenever a new conversation was started. Finally, we simulated a message from the user to the bot, allowing the bot to promptly respond.

This was implemented like this.


```csharp
if (activity.Type == ActivityTypes.ContactRelationUpdate)
{
    // Handle add/remove from contact lists
    // Activity.From + Activity.Action represent what happened
    activity.Text = "action:0";
    using (var scope = DialogModule.BeginLifetimeScope(_scope, activity))
    {
        await Conversation.SendAsync(activity, () => scope.Resolve<IDialog<object>>());
    }
} 
```

#### Bot channels vs. Bot Framework Emulator
 
While working on the project, we made sure to test the solution in some of the bot channels (Messenger, Skype) and the [Bot Framework Emulator](https://docs.botframework.com/en-us/tools/bot-framework-emulator/). The emulator allows for very rapid testing while developing, but there are differences between many of the bot channels and the emulator. Some of these differences were discovered as we were testing, and some were documented. 

We noticed that the bot channels would add to the conversation on behalf of the user when pushing a card/button action. This behavior isn't found in the emulator. This behavior created more of a conversation between the user and the bot, generating a history of card/button actions taken by the user.

If the conversation includes sensitive subject matter (as in this case), the user should be informed about this.

The key take away is that testing is crucial for any bot channels you're targeting.   
<br/>
![Added Message By Pressing Card/Button Action]({{ site.baseurl }}/images/brisbot/postback.png)  
<br/>
#### UX considerations

Initially we wanted to show the actions as buttons grouped on a single card.  
<br/>
![Actions as buttons]({{ site.baseurl }}/images/brisbot/actions_as_buttons.png)  
<br/>
This gives a very good overview of the possible actions. Unfortunately, some of the action texts are long and won't fit on a button.  This makes it impossible for the user to decide if this is a good choice.

Therefore we decided to display all actions as separate cards grouped in a carousel. This makes it slightly harder to get an overview of all the options, but on the other hand, you can see the full text of the options.  

![Action cards in a carousel]({{ site.baseurl }}/images/brisbot/actions_as_carousel.png)   

## Conclusion

This project demonstrates the ability to provide a solution to customers, wherever they are. Not only does it have a great reach with the Bot Framework, but it's also developed in a maintainable fashion with a common code base. It leverages technologies and development stacks that the customer can take care of, ensuring the future of the project.

By allowing the dialogs with their cards and buttons to be driven by data storage, we were able to build this solution in a matter of days. Hard-coding the same solution with its content would have taken signficantly more time. A great takeaway is that this approach can be very suitable for anyone building a dynamic bot experience.

The scope of the efforts laid the foundation for continued investments, such as the integration of [Cognitive Services](https://www.microsoft.com/cognitive-services/en-us/apis) to further enhance the experience. Using Cognitive Services, the customer will be able to perform text analytics and start understanding the sentiments, key phrases, topics, and languages in the interactions. 

Other opportunities have emerged as well, such as investigating the place for [Azure DocumentDB](https://azure.microsoft.com/en-us/services/documentdb/) in the architecture. This goes well in hand with the future to integrate a management interface on top of the data model, to allow for easy management of the content provided via the bot. 

Furthermore, investments by the customer into security and data persistence will be crucial. This was always outside the scope of this project, but something that was thought about. Due to the potentially sensitive nature of the data, data classification and secure persistence practices must be designed and implemented. 

Finally, the entire deployment should be automated using [ARM templates](https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-overview).

Designing a solution where the interactions (between user and solution) could potentially entail deeply personal matters is not an easy task. We have had to be very delicate and mindful when creating the solution, and this should be the case for anyone building something similar.

In our case, this meant that we didn't allow for any free-text. The entire solution is driven by card/button actions. In further investments, this area could be explored and evaluated with care.

Understanding the requirements of such interactions needs close collaboration between professionals. While we had the opportunity to showcase the capabilities of these technologies - it will be up to the customer going forward to continuously ensure the integrity and quality of the interactions. 

We decided to wrap up the code as a sample, for anyone interested in building a bot like this. In addition, we created a [walk-through video on how to get started with the sample](https://channel9.msdn.com/Events/Microsoft-Partner-Network/Kompis-Sverige/Dynamic-Dialog-Bot-Sample).


## Additional resources

- [Dynamic Dialog Bot Sample](https://github.com/simonjaeger/dynamic-dialog-bot-sample)
- [Bris in English](https://www.bris.se/languages/)
- [Bot Framework](https://dev.botframework.com/)
- [Azure SQL Database](https://azure.microsoft.com/en-us/services/sql-database/?b=16.50)
